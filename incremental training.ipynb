{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b298e535",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4750b52",
   "metadata": {
    "papermill": {
     "duration": 0.012142,
     "end_time": "2024-10-31T07:35:27.937709",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.925567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 增量训练\n",
    "\n",
    "要说什么你自己 GPT 吧 记得多放一放跑出来的结果就行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca90262",
   "metadata": {
    "papermill": {
     "duration": 0.001493,
     "end_time": "2024-10-31T07:35:27.941222",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.939729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "现在你帮我把 weekData 里面的数据，分成不同文件，命名就 1，2，3，4，5 这种，要求，最多1073张文件在一起，但是有的时间数据缺失了，如果缺失超过25分钟的数据，也就是5张，那也要分开文件，比如 190000 下一张是 193000，就要分开他们，直接在 weekData 里面生成 weekData/1 weekData/2 weekData/3 weekData/4 这种  \n",
    "|  \n",
    "记得提到, API 的问题,有一些文件缺失,所以我们把不连续的图片分隔开,成为不同的图片集,来做增量训练,我总共会训练 8周的数据  \n",
    "288(第一次训练) + 16055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9c405a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:27.945258Z",
     "iopub.status.busy": "2024-10-31T07:35:27.945258Z",
     "iopub.status.idle": "2024-10-31T07:35:27.957353Z",
     "shell.execute_reply": "2024-10-31T07:35:27.956849Z"
    },
    "papermill": {
     "duration": 0.013597,
     "end_time": "2024-10-31T07:35:27.957353",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.943756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 设置文件夹路径\n",
    "data_folder = './weekData'\n",
    "output_folder = './weekData'\n",
    "max_files_per_folder = 288\n",
    "max_gap_minutes = 25  # 25分钟，即5个文件\n",
    "\n",
    "# 获取文件名列表并按时间排序\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(data_folder) if f.endswith('.png')],\n",
    "    key=lambda x: datetime.strptime(x.split('_')[2][:12], '%Y%m%d%H%M')  # 提取和解析时间字符串\n",
    ")\n",
    "\n",
    "# 初始化变量\n",
    "current_folder_index = 5\n",
    "current_batch = []\n",
    "previous_time = None\n",
    "\n",
    "# 遍历文件并进行分组\n",
    "for file_name in file_list:\n",
    "    # 提取当前文件的时间戳\n",
    "    timestamp_str = file_name.split('_')[2][:12]  # 提取时间部分并截取到分钟\n",
    "    current_time = datetime.strptime(timestamp_str, '%Y%m%d%H%M')\n",
    "\n",
    "    # 判断是否需要新建一个文件夹\n",
    "    if (\n",
    "        previous_time is None or  # 如果是第一个文件\n",
    "        len(current_batch) >= max_files_per_folder or  # 当前文件夹已达到最大数量\n",
    "        (current_time - previous_time > timedelta(minutes=max_gap_minutes))  # 时间间隔超过最大限制\n",
    "    ):\n",
    "        # 如果当前文件夹非空，则保存当前批次文件到新文件夹\n",
    "        if current_batch:\n",
    "            target_folder = os.path.join(output_folder, str(current_folder_index))\n",
    "            os.makedirs(target_folder, exist_ok=True)\n",
    "            for f in current_batch:\n",
    "                shutil.move(os.path.join(data_folder, f), os.path.join(target_folder, f))\n",
    "            print(f\"Created folder {target_folder} with {len(current_batch)} files.\")\n",
    "\n",
    "            # 更新文件夹编号\n",
    "            current_folder_index += 1\n",
    "            current_batch = []\n",
    "\n",
    "    # 将当前文件添加到批次中\n",
    "    current_batch.append(file_name)\n",
    "    previous_time = current_time\n",
    "\n",
    "# 将最后一批文件保存到新文件夹\n",
    "if current_batch:\n",
    "    target_folder = os.path.join(output_folder, str(current_folder_index))\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    for f in current_batch:\n",
    "        shutil.move(os.path.join(data_folder, f), os.path.join(target_folder, f))\n",
    "    print(f\"Created folder {target_folder} with {len(current_batch)} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4935f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:27.961565Z",
     "iopub.status.busy": "2024-10-31T07:35:27.961565Z",
     "iopub.status.idle": "2024-10-31T07:35:27.971825Z",
     "shell.execute_reply": "2024-10-31T07:35:27.971825Z"
    },
    "papermill": {
     "duration": 0.011958,
     "end_time": "2024-10-31T07:35:27.971825",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.959867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # 父文件夹路径\n",
    "# parent_folder = './weekData'\n",
    "\n",
    "# # 遍历 1 到 9 的子文件夹\n",
    "# for i in range(5, 28):\n",
    "#     sub_folder = os.path.join(parent_folder, str(i))\n",
    "    \n",
    "#     # 检查子文件夹是否存在\n",
    "#     if os.path.exists(sub_folder):\n",
    "#         # 遍历子文件夹中的所有文件\n",
    "#         for file_name in os.listdir(sub_folder):\n",
    "#             file_path = os.path.join(sub_folder, file_name)\n",
    "#             # 将文件移动到父文件夹\n",
    "#             if os.path.isfile(file_path):  # 确保只移动文件，忽略文件夹\n",
    "#                 shutil.move(file_path, parent_folder)\n",
    "#         # 删除空的子文件夹\n",
    "#         os.rmdir(sub_folder)\n",
    "#     else:\n",
    "#         print(f\"子文件夹 {sub_folder} 不存在，跳过。\")\n",
    "\n",
    "# print(\"文件已成功移动到父文件夹 ./weekData。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc7825",
   "metadata": {
    "papermill": {
     "duration": 0.001002,
     "end_time": "2024-10-31T07:35:27.975510",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.974508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 开始增量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea21162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:27.979015Z",
     "iopub.status.busy": "2024-10-31T07:35:27.979015Z",
     "iopub.status.idle": "2024-10-31T07:35:31.763954Z",
     "shell.execute_reply": "2024-10-31T07:35:31.763954Z"
    },
    "papermill": {
     "duration": 3.787452,
     "end_time": "2024-10-31T07:35:31.764962",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.977510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def get_next_model_step(folder_path='./Models/Add/'):\n",
    "    # 匹配文件名的正则表达式\n",
    "    model_pattern = re.compile(r'SP480_(\\d+)\\.h5')\n",
    "    \n",
    "    # 获取文件夹中的所有文件\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # 找到所有符合 SP480_X.h5 命名格式的文件，并提取编号\n",
    "    model_numbers = []\n",
    "    for file in files:\n",
    "        match = model_pattern.match(file)\n",
    "        if match:\n",
    "            model_numbers.append(int(match.group(1)))\n",
    "\n",
    "    # 如果找到模型文件，返回最大编号 + 1；否则返回 1\n",
    "    return max(model_numbers) + 1 if model_numbers else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bfcf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:31.780158Z",
     "iopub.status.busy": "2024-10-31T07:35:31.780158Z",
     "iopub.status.idle": "2024-10-31T07:35:32.360666Z",
     "shell.execute_reply": "2024-10-31T07:35:32.360666Z"
    },
    "papermill": {
     "duration": 0.583676,
     "end_time": "2024-10-31T07:35:32.361666",
     "exception": false,
     "start_time": "2024-10-31T07:35:31.777990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readPicture(times, model):\n",
    "# 输入文件夹路径\n",
    "    input_folder = './weekData/' + str(times)\n",
    "\n",
    "    # 初始化列表来存放原始和处理后的图片\n",
    "    original_images = []\n",
    "    processed_images = []\n",
    "\n",
    "    # 设置最小降雨面积阈值\n",
    "    min_rain_area = 10  # 可根据需要调整\n",
    "\n",
    "    # 遍历文件夹中的每张图片\n",
    "    for filename in sorted(os.listdir(input_folder)):\n",
    "        # 检查是否为图片文件\n",
    "        if filename.endswith('.png'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # Step 1: 读取图片\n",
    "            img = cv2.imread(input_path)\n",
    "            if img is None:\n",
    "                print(f\"Error: 图片 {filename} 未成功加载，跳过此文件。\")\n",
    "                continue\n",
    "            \n",
    "            # Step 2: 灰度化处理\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Step 3: 保存未处理的灰度图像到 original_images\n",
    "            original_images.append(gray_img)\n",
    "            \n",
    "            # Step 4: 二值化处理\n",
    "            _, binary_img = cv2.threshold(gray_img, 30, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Step 5: 去除小面积区域\n",
    "            binary_img = morphology.remove_small_objects(binary_img.astype(bool), min_rain_area)\n",
    "            binary_img = (binary_img * 255).astype(np.uint8)\n",
    "            \n",
    "            # Step 6: 应用掩码\n",
    "            processed_img = cv2.bitwise_and(gray_img, gray_img, mask=binary_img)\n",
    "            \n",
    "            # Step 7: 归一化\n",
    "            normalized_img = (processed_img / 255.0)  # 归一化到 0-1 区间\n",
    "            \n",
    "            # 将处理后的图像添加到 processed_images\n",
    "            processed_images.append(normalized_img)\n",
    "\n",
    "    # print(\"图片处理完成。`original_images` 和 `processed_images` 数据已准备好。\")\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c378d9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:32.376495Z",
     "iopub.status.busy": "2024-10-31T07:35:32.376495Z",
     "iopub.status.idle": "2024-10-31T07:35:32.392016Z",
     "shell.execute_reply": "2024-10-31T07:35:32.392016Z"
    },
    "papermill": {
     "duration": 0.018964,
     "end_time": "2024-10-31T07:35:32.393017",
     "exception": false,
     "start_time": "2024-10-31T07:35:32.374053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ConvLSTM2D, TimeDistributed, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def setDataShape(processed_images):\n",
    "    # 假设 processed_images 已经准备好，每个图像大小为 (480, 480)\n",
    "    processed_images = np.array(processed_images)  # 转换成 NumPy 数组\n",
    "    processed_images = processed_images[..., np.newaxis]  # 添加单通道 (480, 480) -> (480, 480, 1)\n",
    "\n",
    "    time_steps = 12  # 输入时间步\n",
    "    pred_steps = 12  # 预测时间步\n",
    "    num_samples = len(processed_images) - time_steps - pred_steps + 1\n",
    "\n",
    "    # 构建输入和输出数据\n",
    "    X_train = np.array([processed_images[i:i + time_steps] for i in range(num_samples)])\n",
    "    y_train = np.array([processed_images[i + time_steps:i + time_steps + pred_steps] for i in range(num_samples)])\n",
    "\n",
    "    # print(\"增量训练数据形状:\")\n",
    "    # print(\"X_train shape:\", X_train.shape)  # (num_samples, time_steps, 480, 480, 1)\n",
    "    # print(\"y_train shape:\", y_train.shape)  # (num_samples, pred_steps, 480, 480, 1)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def data_generator(processed_images, time_steps, pred_steps, batch_size):\n",
    "    num_samples = len(processed_images) - time_steps - pred_steps + 1\n",
    "    while True:\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X = np.array([processed_images[j:j + time_steps] for j in range(i, min(i + batch_size, num_samples))], dtype=np.float32)\n",
    "            y = np.array([processed_images[j + time_steps:j + time_steps + pred_steps] for j in range(i, min(i + batch_size, num_samples))], dtype=np.float32)\n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd398fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:32.396765Z",
     "iopub.status.busy": "2024-10-31T07:35:32.396765Z",
     "iopub.status.idle": "2024-10-31T07:35:33.407365Z",
     "shell.execute_reply": "2024-10-31T07:35:33.406824Z"
    },
    "papermill": {
     "duration": 1.013348,
     "end_time": "2024-10-31T07:35:33.407365",
     "exception": false,
     "start_time": "2024-10-31T07:35:32.394017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def test(model):\n",
    "# 文件夹路径\n",
    "    test_folder = './dataOneDayTest'\n",
    "    time_steps = 12\n",
    "    pred_steps = 12\n",
    "\n",
    "    # 加载测试图像数据并预处理\n",
    "    test_images = []\n",
    "    image_files = sorted([f for f in os.listdir(test_folder) if f.endswith('.png')])\n",
    "    for file in image_files:\n",
    "        img = cv2.imread(os.path.join(test_folder, file), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img, (480, 480), interpolation=cv2.INTER_AREA)\n",
    "        normalized_img = resized_img / 255.0  # 归一化\n",
    "        test_images.append(normalized_img)\n",
    "\n",
    "    # 转换成 NumPy 数组并添加通道维度\n",
    "    test_images = np.array(test_images)[..., np.newaxis]  # 形状: (24, 480, 480, 1)\n",
    "\n",
    "    # 准备测试输入数据\n",
    "    X_test = np.array([test_images[i:i + time_steps] for i in range(len(test_images) - time_steps - pred_steps + 1)])\n",
    "    y_actual = np.array([test_images[i + time_steps:i + time_steps + pred_steps] for i in range(len(test_images) - time_steps - pred_steps + 1)])\n",
    "\n",
    "    # print(\"X_test shape:\", X_test.shape)  # (num_samples, time_steps, 480, 480, 1)\n",
    "    # print(\"y_actual shape:\", y_actual.shape)  # (num_samples, pred_steps, 480, 480, 1)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 计算 MSE, MAE 和 SSIM\n",
    "    mse = mean_squared_error(y_actual.flatten(), y_pred.flatten())\n",
    "    mae = mean_absolute_error(y_actual.flatten(), y_pred.flatten())\n",
    "\n",
    "    # 计算结构相似性（SSIM）\n",
    "    ssim_scores = []\n",
    "    for i in range(pred_steps):\n",
    "        ssim_score = ssim(y_actual[0, i, :, :, 0], y_pred[0, i, :, :, 0], data_range=1.0)\n",
    "        ssim_scores.append(ssim_score)\n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "\n",
    "    # 输出评估指标\n",
    "    print(f\"Mean Squared Error (MSE) on Test Set: {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE) on Test Set: {mae}\")\n",
    "    print(f\"Mean Structural Similarity (SSIM) on Test Set: {mean_ssim}\")\n",
    "\n",
    "    # 可视化前几个预测和实际结果的对比\n",
    "    fig, axs = plt.subplots(12, 2, figsize=(10, 40))\n",
    "    for i in range(12):\n",
    "        # 显示预测结果\n",
    "        axs[i, 0].imshow(y_pred[0, i, :, :, 0], cmap='gray')\n",
    "        axs[i, 0].set_title(f\"Predicted Frame {i+1}\")\n",
    "        axs[i, 0].axis('off')\n",
    "        \n",
    "        # 显示实际结果\n",
    "        axs[i, 1].imshow(y_actual[0, i, :, :, 0], cmap='gray')\n",
    "        axs[i, 1].set_title(f\"Actual Frame {i+1}\")\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return mse,mae,mean_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f003bd5",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c22d4f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:33.422735Z",
     "iopub.status.busy": "2024-10-31T07:35:33.422735Z",
     "iopub.status.idle": "2024-10-31T07:35:39.619570Z",
     "shell.execute_reply": "2024-10-31T07:35:39.618880Z"
    },
    "papermill": {
     "duration": 6.199342,
     "end_time": "2024-10-31T07:35:39.620074",
     "exception": true,
     "start_time": "2024-10-31T07:35:33.420732",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下一个模型编号为：51\n",
      "\n",
      "正在进行第 51 次微调和测试...\n",
      "Epoch 1/9\n",
      "265/265 [==============================] - 60s 202ms/step - loss: 0.0025\n",
      "Epoch 2/9\n",
      "225/265 [========================>.....] - ETA: 8s - loss: 0.0025"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Reol\\AppData\\Local\\Temp\\ipykernel_10332\\2433934260.py\", line 47, in <module>\n      history = model.fit(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[12,480,480,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5207]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     45\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(processed_images) \u001b[38;5;241m-\u001b[39m time_steps \u001b[38;5;241m-\u001b[39m pred_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 最多 300 个 epoch\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 使用 EarlyStopping\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 保存微调后的模型\u001b[39;00m\n\u001b[0;32m     55\u001b[0m fine_tuned_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Models/Add/SP480_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32me:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Reol\\AppData\\Local\\Temp\\ipykernel_10332\\2433934260.py\", line 47, in <module>\n      history = model.fit(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[12,480,480,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5207]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "start_from = get_next_model_step()\n",
    "print(f\"下一个模型编号为：{start_from}\")\n",
    "max_times = 56\n",
    "time_steps = 12\n",
    "pred_steps = 12\n",
    "\n",
    "# 设置早停回调\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# 执行 16 次微调和测试\n",
    "for times in range(start_from, max_times+1):\n",
    "\n",
    "        \n",
    "    # 加载已有的模型\n",
    "    model_path = './Models/Add/SP480_'+str(times-1)+'.h5'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # 设置增量训练参数\n",
    "    learning_rate = 1e-5  # 设置较低的学习率\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "    print(f\"\\n正在进行第 {times} 次微调和测试...\")\n",
    "\n",
    "    # 清理显存和重置模型状态\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # 读取当前批次的图片\n",
    "    processed_images = readPicture(times, model)\n",
    "\n",
    "    # 调用 setDataShape 函数获取训练数据\n",
    "    X_train, y_train = setDataShape(processed_images)\n",
    "\n",
    "    # 设置批次大小和每轮训练的步数\n",
    "    batch_size = 8\n",
    "    steps_per_epoch = (len(processed_images) - time_steps - pred_steps + 1) // batch_size\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=9,              # 最多 300 个 epoch\n",
    "        batch_size=1,\n",
    "        callbacks=[early_stopping]  # 使用 EarlyStopping\n",
    "    )\n",
    "\n",
    "    # 保存微调后的模型\n",
    "    fine_tuned_model_path = f'./Models/Add/SP480_{times}.h5'\n",
    "    model.save(fine_tuned_model_path)\n",
    "    # print(f\"微调后的模型已保存至 {fine_tuned_model_path}\")\n",
    "\n",
    "    # 调用测试函数，并存储结果\n",
    "    # mse, mae, mean_ssim = test(model)\n",
    "    # test_results[times] = [mse, mae, mean_ssim]  # 存储到数组中\n",
    "\n",
    "    # print(f\"第 {times} 次测试结果 - MSE: {mse}, MAE: {mae}, SSIM: {mean_ssim}\")\n",
    "\n",
    "# # 打印所有的测试结果\n",
    "# print(\"\\n所有测试结果：\")\n",
    "# for i, (mse, mae, mean_ssim) in enumerate(test_results, start=1):\n",
    "#     print(f\"微调后模型 {i}: MSE = {mse}, MAE = {mae}, SSIM = {mean_ssim}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.018005,
   "end_time": "2024-10-31T07:35:40.604157",
   "environment_variables": {},
   "exception": true,
   "input_path": "incremental training.ipynb",
   "output_path": "incremental training.ipynb",
   "parameters": {},
   "start_time": "2024-10-31T07:35:26.586152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
