{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4750b52",
   "metadata": {
    "papermill": {
     "duration": 0.012142,
     "end_time": "2024-10-31T07:35:27.937709",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.925567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Incremental Training\n",
    "We used an additional 50 days of data to run incremental learning. Due to hardware limitations,   \n",
    "we split the 50 days of data into 50 datasets and ran them sequentially, resulting in 50+1 models.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9c405a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:27.945258Z",
     "iopub.status.busy": "2024-10-31T07:35:27.945258Z",
     "iopub.status.idle": "2024-10-31T07:35:27.957353Z",
     "shell.execute_reply": "2024-10-31T07:35:27.956849Z"
    },
    "papermill": {
     "duration": 0.013597,
     "end_time": "2024-10-31T07:35:27.957353",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.943756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#  Set folder paths\n",
    "data_folder = './weekData'\n",
    "output_folder = './weekData'\n",
    "max_files_per_folder = 288\n",
    "max_gap_minutes = 25  # 25 minutes, equivalent to 5 files\n",
    "\n",
    "#  Get list of file names and sort by time\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(data_folder) if f.endswith('.png')],\n",
    "    key=lambda x: datetime.strptime(x.split('_')[2][:12], '%Y%m%d%H%M')  # Extract and parse the timestamp string\n",
    ")\n",
    "\n",
    "#  Initialize variables\n",
    "current_folder_index = 5\n",
    "current_batch = []\n",
    "previous_time = None\n",
    "\n",
    "#  Iterate through files and group them\n",
    "for file_name in file_list:\n",
    "    #  Extract timestamp from the current file\n",
    "    timestamp_str = file_name.split('_')[2][:12]  # Extract time part and take up to minutes\n",
    "    current_time = datetime.strptime(timestamp_str, '%Y%m%d%H%M')\n",
    "\n",
    "    #  Check if a new folder is needed\n",
    "    if (\n",
    "        previous_time is None or  # If it's the first file\n",
    "        len(current_batch) >= max_files_per_folder or  # Current folder has reached max number of files\n",
    "        (current_time - previous_time > timedelta(minutes=max_gap_minutes))  # Time gap exceeds the max limit\n",
    "    ):\n",
    "        #  If the current folder is not empty, save the current batch of files to a new folder\n",
    "        if current_batch:\n",
    "            target_folder = os.path.join(output_folder, str(current_folder_index))\n",
    "            os.makedirs(target_folder, exist_ok=True)\n",
    "            for f in current_batch:\n",
    "                shutil.move(os.path.join(data_folder, f), os.path.join(target_folder, f))\n",
    "            print(f\"Created folder {target_folder} with {len(current_batch)} files.\")\n",
    "\n",
    "            #  Update folder index\n",
    "            current_folder_index += 1\n",
    "            current_batch = []\n",
    "\n",
    "    #  Add the current file to the batch\n",
    "    current_batch.append(file_name)\n",
    "    previous_time = current_time\n",
    "\n",
    "#  Save the last batch of files to a new folder\n",
    "if current_batch:\n",
    "    target_folder = os.path.join(output_folder, str(current_folder_index))\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    for f in current_batch:\n",
    "        shutil.move(os.path.join(data_folder, f), os.path.join(target_folder, f))\n",
    "    print(f\"Created folder {target_folder} with {len(current_batch)} files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc7825",
   "metadata": {
    "papermill": {
     "duration": 0.001002,
     "end_time": "2024-10-31T07:35:27.975510",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.974508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea21162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:27.979015Z",
     "iopub.status.busy": "2024-10-31T07:35:27.979015Z",
     "iopub.status.idle": "2024-10-31T07:35:31.763954Z",
     "shell.execute_reply": "2024-10-31T07:35:31.763954Z"
    },
    "papermill": {
     "duration": 3.787452,
     "end_time": "2024-10-31T07:35:31.764962",
     "exception": false,
     "start_time": "2024-10-31T07:35:27.977510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def get_next_model_step(folder_path='./Models/Add/'):\n",
    "    #  Regular expression to match file names\n",
    "    model_pattern = re.compile(r'SP480_(\\d+)\\.h5')\n",
    "    \n",
    "    #  Get all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    #  Find all files matching the SP480_X.h5 naming format and extract numbers\n",
    "    model_numbers = []\n",
    "    for file in files:\n",
    "        match = model_pattern.match(file)\n",
    "        if match:\n",
    "            model_numbers.append(int(match.group(1)))\n",
    "\n",
    "    #  If model files are found, return the max number + 1; otherwise, return 1\n",
    "    return max(model_numbers) + 1 if model_numbers else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bfcf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:31.780158Z",
     "iopub.status.busy": "2024-10-31T07:35:31.780158Z",
     "iopub.status.idle": "2024-10-31T07:35:32.360666Z",
     "shell.execute_reply": "2024-10-31T07:35:32.360666Z"
    },
    "papermill": {
     "duration": 0.583676,
     "end_time": "2024-10-31T07:35:32.361666",
     "exception": false,
     "start_time": "2024-10-31T07:35:31.777990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readPicture(times, model):\n",
    "    #  Input folder path\n",
    "    input_folder = './weekData/' + str(times)\n",
    "\n",
    "    #  Initialize lists to store original and processed images\n",
    "    original_images = []\n",
    "    processed_images = []\n",
    "\n",
    "    #  Set minimum rain area threshold\n",
    "    min_rain_area = 10  # Adjust as needed\n",
    "\n",
    "    #  Iterate through each image in the folder\n",
    "    for filename in sorted(os.listdir(input_folder)):\n",
    "        #  Check if the file is an image\n",
    "        if filename.endswith('.png'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            #  Step 1: Read the image\n",
    "            img = cv2.imread(input_path)\n",
    "            if img is None:\n",
    "                print(f\"Error: Image {filename} failed to load, skipping this file.\")\n",
    "                continue\n",
    "            \n",
    "            #  Step 2: Convert to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #  Step 3: Save the unprocessed grayscale image to original_images\n",
    "            original_images.append(gray_img)\n",
    "            \n",
    "            #  Step 4: Apply binary thresholding\n",
    "            _, binary_img = cv2.threshold(gray_img, 30, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            #  Step 5: Remove small areas\n",
    "            binary_img = morphology.remove_small_objects(binary_img.astype(bool), min_rain_area)\n",
    "            binary_img = (binary_img * 255).astype(np.uint8)\n",
    "            \n",
    "            #  Step 6: Apply mask\n",
    "            processed_img = cv2.bitwise_and(gray_img, gray_img, mask=binary_img)\n",
    "            \n",
    "            #  Step 7: Normalize\n",
    "            normalized_img = (processed_img / 255.0)  # Normalize to 0-1 range\n",
    "            \n",
    "            #  Add processed image to processed_images\n",
    "            processed_images.append(normalized_img)\n",
    "\n",
    "    # print(\"Image processing complete. `original_images` and `processed_images` data are ready.\")\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c378d9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:32.376495Z",
     "iopub.status.busy": "2024-10-31T07:35:32.376495Z",
     "iopub.status.idle": "2024-10-31T07:35:32.392016Z",
     "shell.execute_reply": "2024-10-31T07:35:32.392016Z"
    },
    "papermill": {
     "duration": 0.018964,
     "end_time": "2024-10-31T07:35:32.393017",
     "exception": false,
     "start_time": "2024-10-31T07:35:32.374053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ConvLSTM2D, TimeDistributed, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def setDataShape(processed_images):\n",
    "    #  Assume processed_images is ready, with each image size of (480, 480)\n",
    "    processed_images = np.array(processed_images)  # Convert to NumPy array\n",
    "    processed_images = processed_images[..., np.newaxis]  # Add a single channel (480, 480) -> (480, 480, 1)\n",
    "\n",
    "    time_steps = 12  # Input time steps\n",
    "    pred_steps = 12  # Prediction time steps\n",
    "    num_samples = len(processed_images) - time_steps - pred_steps + 1\n",
    "\n",
    "    #  Build input and output data\n",
    "    X_train = np.array([processed_images[i:i + time_steps] for i in range(num_samples)])\n",
    "    y_train = np.array([processed_images[i + time_steps:i + time_steps + pred_steps] for i in range(num_samples)])\n",
    "\n",
    "    # print(\"Incremental training data shapes:\")\n",
    "    # print(\"X_train shape:\", X_train.shape)  # (num_samples, time_steps, 480, 480, 1)\n",
    "    # print(\"y_train shape:\", y_train.shape)  # (num_samples, pred_steps, 480, 480, 1)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def data_generator(processed_images, time_steps, pred_steps, batch_size):\n",
    "    num_samples = len(processed_images) - time_steps - pred_steps + 1\n",
    "    while True:\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X = np.array([processed_images[j:j + time_steps] for j in range(i, min(i + batch_size, num_samples))], dtype=np.float32)\n",
    "            y = np.array([processed_images[j + time_steps:j + time_steps + pred_steps] for j in range(i, min(i + batch_size, num_samples))], dtype=np.float32)\n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd398fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:32.396765Z",
     "iopub.status.busy": "2024-10-31T07:35:32.396765Z",
     "iopub.status.idle": "2024-10-31T07:35:33.407365Z",
     "shell.execute_reply": "2024-10-31T07:35:33.406824Z"
    },
    "papermill": {
     "duration": 1.013348,
     "end_time": "2024-10-31T07:35:33.407365",
     "exception": false,
     "start_time": "2024-10-31T07:35:32.394017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def test(model):\n",
    "    #  Folder path\n",
    "    test_folder = './dataOneDayTest'\n",
    "    time_steps = 12\n",
    "    pred_steps = 12\n",
    "\n",
    "    #  Load and preprocess test image data\n",
    "    test_images = []\n",
    "    image_files = sorted([f for f in os.listdir(test_folder) if f.endswith('.png')])\n",
    "    for file in image_files:\n",
    "        img = cv2.imread(os.path.join(test_folder, file), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img, (480, 480), interpolation=cv2.INTER_AREA)\n",
    "        normalized_img = resized_img / 255.0  # Normalize\n",
    "        test_images.append(normalized_img)\n",
    "\n",
    "    #  Convert to NumPy array and add channel dimension\n",
    "    test_images = np.array(test_images)[..., np.newaxis]  # Shape: (24, 480, 480, 1)\n",
    "\n",
    "    #  Prepare test input data\n",
    "    X_test = np.array([test_images[i:i + time_steps] for i in range(len(test_images) - time_steps - pred_steps + 1)])\n",
    "    y_actual = np.array([test_images[i + time_steps:i + time_steps + pred_steps] for i in range(len(test_images) - time_steps - pred_steps + 1)])\n",
    "\n",
    "    # print(\"X_test shape:\", X_test.shape)  # (num_samples, time_steps, 480, 480, 1)\n",
    "    # print(\"y_actual shape:\", y_actual.shape)  # (num_samples, pred_steps, 480, 480, 1)\n",
    "\n",
    "    #  Predict using the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #  Calculate MSE, MAE, and SSIM\n",
    "    mse = mean_squared_error(y_actual.flatten(), y_pred.flatten())\n",
    "    mae = mean_absolute_error(y_actual.flatten(), y_pred.flatten())\n",
    "\n",
    "    #  Calculate Structural Similarity (SSIM)\n",
    "    ssim_scores = []\n",
    "    for i in range(pred_steps):\n",
    "        ssim_score = ssim(y_actual[0, i, :, :, 0], y_pred[0, i, :, :, 0], data_range=1.0)\n",
    "        ssim_scores.append(ssim_score)\n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "\n",
    "    #  Output evaluation metrics\n",
    "    print(f\"Mean Squared Error (MSE) on Test Set: {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE) on Test Set: {mae}\")\n",
    "    print(f\"Mean Structural Similarity (SSIM) on Test Set: {mean_ssim}\")\n",
    "\n",
    "    #  Visualize comparison of the first few predicted and actual results\n",
    "    fig, axs = plt.subplots(12, 2, figsize=(10, 40))\n",
    "    for i in range(12):\n",
    "        #  Display predicted result\n",
    "        axs[i, 0].imshow(y_pred[0, i, :, :, 0], cmap='gray')\n",
    "        axs[i, 0].set_title(f\"Predicted Frame {i+1}\")\n",
    "        axs[i, 0].axis('off')\n",
    "        \n",
    "        #  Display actual result\n",
    "        axs[i, 1].imshow(y_actual[0, i, :, :, 0], cmap='gray')\n",
    "        axs[i, 1].set_title(f\"Actual Frame {i+1}\")\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return mse, mae, mean_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c22d4f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:35:33.422735Z",
     "iopub.status.busy": "2024-10-31T07:35:33.422735Z",
     "iopub.status.idle": "2024-10-31T07:35:39.619570Z",
     "shell.execute_reply": "2024-10-31T07:35:39.618880Z"
    },
    "papermill": {
     "duration": 6.199342,
     "end_time": "2024-10-31T07:35:39.620074",
     "exception": true,
     "start_time": "2024-10-31T07:35:33.420732",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下一个模型编号为：51\n",
      "\n",
      "正在进行第 51 次微调和测试...\n",
      "Epoch 1/9\n",
      "265/265 [==============================] - 60s 202ms/step - loss: 0.0025\n",
      "Epoch 2/9\n",
      "225/265 [========================>.....] - ETA: 8s - loss: 0.0025"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Reol\\AppData\\Local\\Temp\\ipykernel_10332\\2433934260.py\", line 47, in <module>\n      history = model.fit(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[12,480,480,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5207]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     45\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(processed_images) \u001b[38;5;241m-\u001b[39m time_steps \u001b[38;5;241m-\u001b[39m pred_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 最多 300 个 epoch\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 使用 EarlyStopping\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 保存微调后的模型\u001b[39;00m\n\u001b[0;32m     55\u001b[0m fine_tuned_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Models/Add/SP480_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32me:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"E:\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Reol\\AppData\\Local\\Temp\\ipykernel_10332\\2433934260.py\", line 47, in <module>\n      history = model.fit(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"e:\\study-master\\NUSCampus\\sem1\\IND5003\\code\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[12,480,480,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/time_distributed_3/conv2d_2/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5207]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "start_from = get_next_model_step()\n",
    "print(f\"The next model number is: {start_from}\")\n",
    "max_times = 56\n",
    "time_steps = 12\n",
    "pred_steps = 12\n",
    "\n",
    "#  Set up early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "#  Perform 16 rounds of fine-tuning and testing\n",
    "for times in range(start_from, max_times+1):\n",
    "\n",
    "    #  Load the existing model\n",
    "    model_path = './Models/Add/SP480_' + str(times-1) + '.h5'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    #  Set incremental training parameters\n",
    "    learning_rate = 1e-5  # Set a low learning rate\n",
    "\n",
    "    #  Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "    print(f\"\\nStarting fine-tuning and testing round {times}...\")\n",
    "\n",
    "    #  Clear memory and reset model state\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    #  Read the current batch of images\n",
    "    processed_images = readPicture(times, model)\n",
    "\n",
    "    #  Call setDataShape function to get training data\n",
    "    X_train, y_train = setDataShape(processed_images)\n",
    "\n",
    "    #  Set batch size and steps per epoch\n",
    "    batch_size = 8\n",
    "    steps_per_epoch = (len(processed_images) - time_steps - pred_steps + 1) // batch_size\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=9,              # Maximum of 300 epochs\n",
    "        batch_size=1,\n",
    "        callbacks=[early_stopping]  # Use EarlyStopping\n",
    "    )\n",
    "\n",
    "    #  Save the fine-tuned model\n",
    "    fine_tuned_model_path = f'./Models/Add/SP480_{times}.h5'\n",
    "    model.save(fine_tuned_model_path)\n",
    "    # print(f\"Fine-tuned model saved to {fine_tuned_model_path}\")\n",
    "\n",
    "    #  Call test function and store results\n",
    "    # mse, mae, mean_ssim = test(model)\n",
    "    # test_results[times] = [mse, mae, mean_ssim]  # Store in an array\n",
    "\n",
    "    # print(f\"Round {times} test results - MSE: {mse}, MAE: {mae}, SSIM: {mean_ssim}\")\n",
    "\n",
    "# # Print all test results\n",
    "# print(\"\\nAll test results:\")\n",
    "# for i, (mse, mae, mean_ssim) in enumerate(test_results, start=1):\n",
    "#     print(f\"Model {i} after fine-tuning: MSE = {mse}, MAE = {mae}, SSIM = {mean_ssim}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.018005,
   "end_time": "2024-10-31T07:35:40.604157",
   "environment_variables": {},
   "exception": true,
   "input_path": "incremental training.ipynb",
   "output_path": "incremental training.ipynb",
   "parameters": {},
   "start_time": "2024-10-31T07:35:26.586152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
